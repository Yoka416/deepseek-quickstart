
!pip install openai==1.82.0 requests==2.32.3 tqdm==4.67.1 numpy

import os
from glob import glob
from openai import OpenAI
import httpx
import numpy as np
from tqdm import tqdm
import time
import hashlib

print("ğŸš€ å¼€å§‹æœ€å°ä¾èµ–ç‰ˆ RAG ç³»ç»Ÿæµç¨‹...")

# é…ç½®
api_key = "sk-49a710fc14ef46d199fd4c1ded41251c"  # ä½ çš„ DeepSeek API å¯†é’¥

# 1. åŠ è½½æ–‡æ¡£
print("\nğŸ“ æ­£åœ¨åŠ è½½æ–‡æ¡£...")
text_lines = []
file_paths = glob("Downloads/milvus_docs/en/faq/*.md", recursive=True)
print(f"   æ‰¾åˆ° {len(file_paths)} ä¸ªMarkdownæ–‡ä»¶")

for file_path in file_paths:
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            file_text = file.read()
        # æŒ‰æ ‡é¢˜åˆ†å‰²ï¼Œå¹¶è¿‡æ»¤ç©ºè¡Œ
        sections = [section.strip() for section in file_text.split("# ") if section.strip()]
        text_lines.extend(sections)
    except Exception as e:
        print(f"   è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

print(f"   æ€»å…± {len(text_lines)} ä¸ªæ–‡æœ¬æ®µè½")

# 2. åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
print("\nğŸ”— æ­£åœ¨åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯...")
deepseek_client = OpenAI(
    api_key=api_key,
    base_url="https://api.deepseek.com/v1",
    http_client=httpx.Client(verify=False, timeout=60.0)
)
print("   âœ… DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

# 3. ä½¿ç”¨ DeepSeek çš„åµŒå…¥åŠŸèƒ½
print("\nğŸ”§ æ­£åœ¨åˆå§‹åŒ–åµŒå…¥æ¨¡å‹...")

class DeepSeekEmbedding:
    def __init__(self, client):
        self.client = client
        
    def encode_documents(self, texts):
        """æ‰¹é‡ç¼–ç æ–‡æ¡£"""
        print(f"   æ­£åœ¨ç¼–ç  {len(texts)} ä¸ªæ–‡æ¡£...")
        embeddings = []
        
        # åˆ†æ‰¹å¤„ç†é¿å…è¶…é™
        batch_size = 10
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            try:
                response = self.client.embeddings.create(
                    model="text-embedding-3-small",
                    input=batch
                )
                batch_embeddings = [data.embedding for data in response.data]
                embeddings.extend(batch_embeddings)
                print(f"     å·²ç¼–ç  {min(i+batch_size, len(texts))}/{len(texts)} ä¸ªæ–‡æ¡£")
            except Exception as e:
                print(f"     ç¼–ç å¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºå‘é‡æ›¿ä»£")
                # å¤±è´¥æ—¶ä½¿ç”¨éšæœºå‘é‡
                for text in batch:
                    embeddings.append(self._random_embedding(text))
        
        return embeddings
    
    def encode_queries(self, texts):
        """ç¼–ç æŸ¥è¯¢"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=texts
            )
            return [data.embedding for data in response.data]
        except Exception as e:
            print(f"   æŸ¥è¯¢ç¼–ç å¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºå‘é‡")
            return [self._random_embedding(text) for text in texts]
    
    def _random_embedding(self, text):
        """ç”ŸæˆåŸºäºæ–‡æœ¬å“ˆå¸Œçš„ç¡®å®šæ€§éšæœºå‘é‡"""
        # ä½¿ç”¨æ–‡æœ¬å†…å®¹çš„å“ˆå¸Œä½œä¸ºéšæœºç§å­ï¼Œç¡®ä¿ç›¸åŒæ–‡æœ¬ç”Ÿæˆç›¸åŒå‘é‡
        seed = int(hashlib.md5(text.encode()).hexdigest()[:8], 16)
        np.random.seed(seed)
        return np.random.randn(1536).tolist()  # text-embedding-3-small çš„ç»´åº¦

embedding_model = DeepSeekEmbedding(deepseek_client)
print("   âœ… åµŒå…¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")

# 4. ç”ŸæˆåµŒå…¥å‘é‡
print("\nğŸ”¢ æ­£åœ¨ç”ŸæˆåµŒå…¥å‘é‡...")
start_time = time.time()

doc_embeddings = embedding_model.encode_documents(text_lines)
print(f"âœ… åµŒå…¥å®Œæˆ - è€—æ—¶: {time.time() - start_time:.2f}ç§’")
print(f"   ç”Ÿæˆ {len(doc_embeddings)} ä¸ªå‘é‡ï¼Œç»´åº¦: {len(doc_embeddings[0])}")

# 5. è¯­ä¹‰æœç´¢å‡½æ•°
def semantic_search(query, texts, embeddings, top_k=3):
    """ç®€å•çš„è¯­ä¹‰æœç´¢"""
    print(f"   æ­£åœ¨æœç´¢: '{query}'")
    
    # ç¼–ç æŸ¥è¯¢
    query_embeddings = embedding_model.encode_queries([query])
    if not query_embeddings:
        return []
    
    query_embedding = query_embeddings[0]
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    similarities = []
    for i, emb in enumerate(embeddings):
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œè®¡ç®—
            query_vec = np.array(query_embedding)
            doc_vec = np.array(emb)
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(query_vec, doc_vec) / (np.linalg.norm(query_vec) * np.linalg.norm(doc_vec))
            similarities.append((texts[i], float(similarity)))
        except Exception as e:
            print(f"     è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥ {i}: {e}")
            similarities.append((texts[i], 0.0))
    
    # æŒ‰ç›¸ä¼¼åº¦æ’åº
    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:top_k]

# 6. æ‰§è¡Œæœç´¢
print("\nğŸ” æ­£åœ¨æ‰§è¡Œè¯­ä¹‰æœç´¢...")
question = "How is data stored in milvus?"

results = semantic_search(question, text_lines, doc_embeddings)

print("ğŸ“Š æœç´¢ç»“æœ:")
for i, (text, score) in enumerate(results, 1):
    print(f"   {i}. ç›¸ä¼¼åº¦: {score:.3f}")
    # æ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
    preview = text[:100] + "..." if len(text) > 100 else text
    print(f"      å†…å®¹: {preview}")

# 7. ç”Ÿæˆå›ç­”
print("\nğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")

if not results:
    print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœï¼Œæ— æ³•ç”Ÿæˆå›ç­”")
else:
    # æ„å»ºä¸Šä¸‹æ–‡
    context = "\n\n".join([f"ã€ç›¸å…³æ–‡æ¡£ {i}ã€‘\n{text}" for i, (text, score) in enumerate(results, 1)])
    
    SYSTEM_PROMPT = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å‡†ç¡®å›ç­”é—®é¢˜ã€‚"
    USER_PROMPT = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

{context}

é—®é¢˜ï¼š{question}

è¦æ±‚ï¼š
1. åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜å“ªäº›æ–¹é¢æ— æ³•å›ç­”
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€ä¸“ä¸š

è¯·å¼€å§‹å›ç­”ï¼š"""

    start_time = time.time()
    try:
        response = deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": USER_PROMPT},
            ],
            temperature=0.1  # é™ä½éšæœºæ€§ï¼Œä½¿å›ç­”æ›´ç¨³å®š
        )
        
        answer = response.choices[0].message.content
        gen_time = time.time() - start_time

        print("ğŸ‰ å›ç­”ç”Ÿæˆå®Œæˆ!")
        print("=" * 60)
        print(f"ğŸ’¡ é—®é¢˜: {question}")
        print(f"â±ï¸ ç”Ÿæˆè€—æ—¶: {gen_time:.2f}ç§’")
        print("=" * 60)
        print(answer)
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå›ç­”å¤±è´¥: {e}")

print("\nâœ… RAG æµç¨‹æ‰§è¡Œå®Œæ¯•!")
